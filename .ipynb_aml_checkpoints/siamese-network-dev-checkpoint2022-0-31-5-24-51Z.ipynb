{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building One-Shot-Learning with Contrastive Loss Siamese Network\r\n",
        "This experiment will build a custom Siamese Netowrk with contrastive loss to realize One-Shot learning.   \r\n",
        "\r\n",
        "### In a nut shell\r\n",
        "\r\n",
        "We use `Pockemon` to train the SN model to learn about the key texture/feature that can help find similarity between cartoon characters (often raster images) \r\n",
        "\r\n",
        "![network-illustration](https://jixjiastoragegbb.blob.core.windows.net/public/siamese-network/siamese-network-illustration.jpg?sv=2020-08-04&st=2022-01-30T13%3A35%3A34Z&se=2033-01-31T13%3A35%3A00Z&sr=b&sp=r&sig=hs%2BQFg98VOPKSOY5IYXldPAS4oONXdq971qlB3JAtk0%3D)\r\n",
        "\r\n",
        "Then use it to classify other unseen cartoon characters by giving it just **ONE** example (called Template):\r\n",
        "\r\n",
        "![recognize-mario](https://jixjiastoragegbb.blob.core.windows.net/public/siamese-network/siamese-network-one-shot-learn.jpg?sv=2020-08-04&st=2022-01-30T13%3A53%3A35Z&se=2033-01-31T13%3A53%3A00Z&sr=b&sp=r&sig=lWkeKXZsZb6VZGFHI3fgiefmMNTRLMEVtuI%2Bwjn4woc%3D)\r\n",
        "\r\n",
        "Author:  Jixin Jia (Gin)    \r\n",
        "Create Date:   2022/01/30     \r\n",
        "Verion: v1.0 (original draft)\r\n",
        "\r\n",
        "&copy; 2022 Microsoft GBB AI Asia team\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate Azure ML GPU Environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check NVIDIA driver "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \r\n",
        "nvidia-smi"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mon Jan 31 01:21:31 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla M60           On   | 00000001:00:00.0 Off |                  Off |\n| N/A   31C    P8    15W / 150W |      0MiB /  8129MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check TF-GPU version and that GPU is visible "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade tensorflow==2.4.1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "tf_version = tf.__version__\r\n",
        "tf_version = float('.'.join(tf_version.split('.')[:2]))\r\n",
        "\r\n",
        "if tf_version < 2.4:\r\n",
        "    print('Upgrade to use CUDA 11 with Tensorflow > 2.4')\r\n",
        "else:\r\n",
        "    # test GPU is visible\r\n",
        "    tf.config.list_physical_devices('GPU')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-01-31 01:21:40.639172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2022-01-31 01:21:57.906571: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-01-31 01:21:57.908377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n2022-01-31 01:21:58.264645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \npciBusID: 0001:00:00.0 name: Tesla M60 computeCapability: 5.2\ncoreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.94GiB deviceMemoryBandwidth: 149.31GiB/s\n2022-01-31 01:21:58.264705: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n2022-01-31 01:21:58.780999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n2022-01-31 01:21:58.781153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n2022-01-31 01:21:59.126945: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n2022-01-31 01:21:59.280506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n2022-01-31 01:21:59.977249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n2022-01-31 01:22:00.096609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n2022-01-31 01:22:00.138119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n2022-01-31 01:22:00.150980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643592119698
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Setup"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the path to the base output directory\r\n",
        "TRAIN_INPUT = 'train_images/pikachu'\r\n",
        "TRAIN_OUTPUT = 'models'\r\n",
        "\r\n",
        "# model preparation\r\n",
        "IMG_SHAPE = (224, 224, 3)\r\n",
        "MODEL_NAME = 'snn'\r\n",
        "MODEL_PATH = os.path.sep.join([TRAIN_OUTPUT, f'{MODEL_NAME}'])\r\n",
        "MODEL_WEIGHTS_PATH = os.path.sep.join([TRAIN_OUTPUT, f'{MODEL_NAME}.h5'])\r\n",
        "PLOT_PATH = os.path.sep.join([TRAIN_OUTPUT, f'{MODEL_NAME}.png'])"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643592203371
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Image and Preprocess"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from utilities import model_utilities\r\n",
        "from utilities import video_utilities as vu\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "from imutils.paths import list_images\r\n",
        "\r\n",
        "\r\n",
        "# load ID dataset and scale the pixel values to the range of [0, 1]\r\n",
        "print(\"[INFO] Loading dataset...\", end='')\r\n",
        "\r\n",
        "imagePaths = list(list_images(TRAIN_INPUT))\r\n",
        "labels = []\r\n",
        "images = []\r\n",
        "\r\n",
        "for path in imagePaths:\r\n",
        "    # resize to network input shape\r\n",
        "    image = cv2.imread(path)\r\n",
        "    image = cv2.resize(image, (IMG_SHAPE[0], IMG_SHAPE[1]), interpolation = cv2.INTER_AREA)\r\n",
        "    image = img_to_array(image)\r\n",
        "    # normalize to unit scale\r\n",
        "    image = np.array(image, dtype='float')/255.0\r\n",
        "    \r\n",
        "    # save np array images and labels\r\n",
        "    images.append(image)\r\n",
        "    labels.append(os.path.split(os.path.split(path)[0])[-1])  \r\n",
        "\r\n",
        "print(f'Done ({len(images)} loaded)')\r\n",
        "\r\n",
        "# test/train split\r\n",
        "trainX, testX, trainY, testY = train_test_split(images, labels, test_size=0.2)\r\n",
        "\r\n",
        "# prepare the positive and negative pairs\r\n",
        "print(\"[INFO] Preparing positive and negative pairs...\", end='')\r\n",
        "\r\n",
        "(pairTrain, labelTrain), validation = model_utilities.make_pairs(trainX, trainY)\r\n",
        "(pairTest, labelTest), validation = model_utilities.make_pairs(testX, testY)\r\n",
        "print('Done')\r\n",
        "\r\n",
        "print(f'[INFO] Train/Test paris = {len(pairTrain[:,0])}/{len(pairTest[:,0])} (Input shape: {pairTrain[0, 0].shape}/{pairTest[0, 1].shape})')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[INFO] Loading dataset...Done (1165 loaded)\n[INFO] Preparing positive and negative pairs...Done\n[INFO] Train/Test paris = 1864/466 (Input shape: (224, 224, 3)/(224, 224, 3))\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "libpng warning: Duplicate iCCP chunk\nlibpng warning: Incorrect bKGD chunk length\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643592344945
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Transfer Learning Network Architecture"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\r\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\r\n",
        "from tensorflow.keras.layers import Lambda\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\r\n",
        "from tensorflow.keras.layers import AveragePooling2D\r\n",
        "from tensorflow.keras.layers import MaxPooling2D\r\n",
        "import tensorflow.keras.backend as K\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "\r\n",
        "def build_siamese_model(inputShape, embeddingDim=64):\r\n",
        "\t# specify the inputs for the feature extractor network\r\n",
        "\tinputs = Input(inputShape)\r\n",
        "\r\n",
        "\t# define the first set of CONV => RELU => POOL => DROPOUT layers\r\n",
        "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\r\n",
        "\tx = MaxPooling2D(pool_size=(2, 2))(x)\r\n",
        "\tx = Dropout(0.25)(x)\r\n",
        "\t\r\n",
        "\t# second set of CONV => RELU => POOL => DROPOUT layers\r\n",
        "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\r\n",
        "\tx = MaxPooling2D(pool_size=2)(x)\r\n",
        "\tx = Dropout(0.2)(x)\r\n",
        "\r\n",
        "\t# third set of CONV => RELU => POOL => DROPOUT layers\r\n",
        "\tx = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(x)\r\n",
        "\tx = MaxPooling2D(pool_size=2)(x)\r\n",
        "\tx = Dropout(0.1)(x)\r\n",
        "\r\n",
        "\t# prepare the final outputs\r\n",
        "\tx = GlobalAveragePooling2D()(x)\r\n",
        "\toutputs = Dense(embeddingDim)(x)\r\n",
        "\r\n",
        "\t# build the model\r\n",
        "\treturn Model(inputs, outputs)\r\n",
        "\r\n",
        "\r\n",
        "def contrastive_loss(y, preds, margin=0.5):\r\n",
        "    # explicitly cast the true class label data type to the predicted class label\r\n",
        "    y = tf.cast(y, preds.dtype)\r\n",
        "\r\n",
        "    # calculate the contrastive loss between the true labels and the predicted labels\r\n",
        "    squaredPreds = K.square(preds)\r\n",
        "    squaredMargin = K.square(K.maximum(margin - preds, 0))\r\n",
        "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\r\n",
        "\r\n",
        "    # return the computed contrastive loss to the calling function\r\n",
        "    return loss"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643592364859
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model\r\n",
        "Perform `Transfer Learning` on our custom designed Network as feature extraction to process images into vectors.   \r\n",
        "Then use `Contrastive Loss` to compute the Euclidean Distance between two image vectors.    \r\n",
        "Our `Siamese Network` will be taught to identify difference (or similarity) in two images.\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set input size  for network\r\n",
        "BATCH_SIZE = 32\r\n",
        "EPOCHS = 100\r\n",
        "LR = 1e-5\r\n",
        "\r\n",
        "# siamese network as a feature extractor (for fine-tuning)\r\n",
        "print(\"[INFO] Extracting image feature vectors using pre-trained siamese network...\", end='')\r\n",
        "imgA = Input(shape=IMG_SHAPE)\r\n",
        "imgB = Input(shape=IMG_SHAPE)\r\n",
        "featureExtractor = build_siamese_model(IMG_SHAPE)\r\n",
        "featsA = featureExtractor(imgA)\r\n",
        "featsB = featureExtractor(imgB)\r\n",
        "print('Done')\r\n",
        "\r\n",
        "# compute euclidean distance from the two image feature vecs in the Keras lambda layer \r\n",
        "distance = Lambda(model_utilities.euclidean_distance)([featsA, featsB])\r\n",
        "\r\n",
        "# build the full siamese network using the image feature vec as input and distance as output\r\n",
        "print(\"[INFO] Compiling siamese network model...\", end='')\r\n",
        "model = Model(inputs=[imgA, imgB], outputs=distance)\r\n",
        "optimizer = Adam(lr=LR,  decay=LR / EPOCHS)\r\n",
        "model.compile(loss=contrastive_loss, optimizer=optimizer)\r\n",
        "\r\n",
        "print('Done')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[INFO] Extracting image feature vectors using pre-trained siamese network...Done\n[INFO] Compiling siamese network model...Done\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643592431022
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize custom network architecture\r\n",
        "featureExtractor.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 224, 224, 64)      832       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 112, 112, 64)      0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 112, 112, 64)      0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 112, 112, 64)      16448     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 56, 56, 64)        0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 56, 56, 64)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 56, 56, 128)       73856     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 28, 28, 128)       0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 28, 28, 128)       0         \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                8256      \n=================================================================\nTotal params: 99,392\nTrainable params: 99,392\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643592448216
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with Pockemon Dataset\r\n",
        "Train and fine-tune the custom Siamese Network with a specific type of cartoon dataset. Use the model to recognize other unrelated/unseen objects. \r\n",
        "\r\n",
        "![image-alt-text](icons/pikachu_icon.jpg)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\r\n",
        "print(\"[INFO] Begin training...\")\r\n",
        "\r\n",
        "history = model.fit(\r\n",
        "                [pairTrain[:, 0], pairTrain[:, 1]], \r\n",
        "                labelTrain[:],\r\n",
        "                validation_data = (\r\n",
        "                    [pairTest[:, 0], pairTest[:, 1]], \r\n",
        "                    labelTest[:]\r\n",
        "                ),\r\n",
        "                batch_size = BATCH_SIZE,\r\n",
        "                epochs = EPOCHS\r\n",
        "            )\r\n",
        "\r\n",
        "# save trained weights\r\n",
        "print(\"[INFO] Saving model weights...\", end='')\r\n",
        "model.save_weights(MODEL_WEIGHTS_PATH)\r\n",
        "\r\n",
        "# plot the training history\r\n",
        "print(\"[INFO] Plotting training history...\", end='')\r\n",
        "model_utilities.plot_training(history, PLOT_PATH)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[INFO] Begin training...\nEpoch 1/100\n59/59 [==============================] - 33s 442ms/step - loss: 0.1752 - val_loss: 0.0726\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.1052 - val_loss: 0.0732\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0813 - val_loss: 0.0741\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n59/59 [==============================] - 14s 237ms/step - loss: 0.0708 - val_loss: 0.0740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0670 - val_loss: 0.0731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n59/59 [==============================] - 14s 237ms/step - loss: 0.0654 - val_loss: 0.0723\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0669 - val_loss: 0.0715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0633 - val_loss: 0.0709\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0635 - val_loss: 0.0705\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0626 - val_loss: 0.0699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0629 - val_loss: 0.0696\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0618 - val_loss: 0.0694\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0609 - val_loss: 0.0687\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n59/59 [==============================] - 14s 242ms/step - loss: 0.0631 - val_loss: 0.0682\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0605 - val_loss: 0.0681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0611 - val_loss: 0.0678\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0602 - val_loss: 0.0675\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0598 - val_loss: 0.0672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0592 - val_loss: 0.0670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0586 - val_loss: 0.0668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0608 - val_loss: 0.0667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0569 - val_loss: 0.0664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0562 - val_loss: 0.0662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0585 - val_loss: 0.0660\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0572 - val_loss: 0.0660\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0585 - val_loss: 0.0658\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0580 - val_loss: 0.0656\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0596 - val_loss: 0.0655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0575 - val_loss: 0.0653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0584 - val_loss: 0.0654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n59/59 [==============================] - 14s 242ms/step - loss: 0.0553 - val_loss: 0.0652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0578 - val_loss: 0.0651\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0536 - val_loss: 0.0650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0557 - val_loss: 0.0650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0557 - val_loss: 0.0649\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0570 - val_loss: 0.0647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0549 - val_loss: 0.0647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0552 - val_loss: 0.0644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0550 - val_loss: 0.0645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0548 - val_loss: 0.0644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0553 - val_loss: 0.0643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0542 - val_loss: 0.0642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0548 - val_loss: 0.0639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0555 - val_loss: 0.0641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0558 - val_loss: 0.0639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0544 - val_loss: 0.0641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0531 - val_loss: 0.0638\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48/100\n59/59 [==============================] - 14s 241ms/step - loss: 0.0564 - val_loss: 0.0636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0549 - val_loss: 0.0636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0556 - val_loss: 0.0635\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 51/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0536 - val_loss: 0.0633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 52/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0532 - val_loss: 0.0633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 53/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0536 - val_loss: 0.0633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 54/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0532 - val_loss: 0.0630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 55/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0544 - val_loss: 0.0633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 56/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0531 - val_loss: 0.0633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 57/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0545 - val_loss: 0.0631\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 58/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0522 - val_loss: 0.0630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 59/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0547 - val_loss: 0.0628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 60/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0555 - val_loss: 0.0629\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 61/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0518 - val_loss: 0.0630\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 62/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0513 - val_loss: 0.0626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 63/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0543 - val_loss: 0.0627\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 64/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0530 - val_loss: 0.0628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 65/100\n59/59 [==============================] - 14s 241ms/step - loss: 0.0524 - val_loss: 0.0626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 66/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0533 - val_loss: 0.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 67/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0535 - val_loss: 0.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 68/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0523 - val_loss: 0.0626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 69/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0520 - val_loss: 0.0623\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 70/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0528 - val_loss: 0.0626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 71/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0529 - val_loss: 0.0622\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 72/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0530 - val_loss: 0.0623\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 73/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0519 - val_loss: 0.0622\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 74/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0517 - val_loss: 0.0622\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 75/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0517 - val_loss: 0.0620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 76/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0517 - val_loss: 0.0622\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 77/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0534 - val_loss: 0.0618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 78/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0515 - val_loss: 0.0621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 79/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0531 - val_loss: 0.0620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 80/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0521 - val_loss: 0.0619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 81/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0507 - val_loss: 0.0622\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 82/100\n59/59 [==============================] - 14s 241ms/step - loss: 0.0525 - val_loss: 0.0618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 83/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0508 - val_loss: 0.0618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 84/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0505 - val_loss: 0.0620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 85/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0519 - val_loss: 0.0619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 86/100\n59/59 [==============================] - 14s 239ms/step - loss: 0.0531 - val_loss: 0.0618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 87/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0514 - val_loss: 0.0619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 88/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0508 - val_loss: 0.0619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 89/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0513 - val_loss: 0.0619\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 90/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0506 - val_loss: 0.0618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 91/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0512 - val_loss: 0.0618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 92/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0522 - val_loss: 0.0621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 93/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0512 - val_loss: 0.0615\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 94/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0489 - val_loss: 0.0615\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 95/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0496 - val_loss: 0.0616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 96/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0503 - val_loss: 0.0618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 97/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0511 - val_loss: 0.0617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 98/100\n59/59 [==============================] - 14s 242ms/step - loss: 0.0499 - val_loss: 0.0614\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 99/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0500 - val_loss: 0.0616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 100/100\n59/59 [==============================] - 14s 238ms/step - loss: 0.0488 - val_loss: 0.0615\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[INFO] Saving model weights...[INFO] Plotting training history..."
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643550608103
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Inference on Unseen Objects \r\n",
        "e.g. Mario, Megaman, Doraemon"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reload Model "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "\r\n",
        "# use existing model architecture (model)\r\n",
        "print(\"[INFO] Compiling model...\", end='')\r\n",
        "imgA = Input(shape=IMG_SHAPE)\r\n",
        "imgB = Input(shape=IMG_SHAPE)\r\n",
        "featureExtractor = build_siamese_model(IMG_SHAPE)\r\n",
        "featsA = featureExtractor(imgA)\r\n",
        "featsB = featureExtractor(imgB)\r\n",
        "\r\n",
        "distance = Lambda(model_utilities.euclidean_distance)([featsA, featsB])\r\n",
        "model = Model(inputs=[imgA, imgB], outputs=distance)\r\n",
        "optimizer = Adam(lr=LR,  decay=LR / EPOCHS) #compile\r\n",
        "model.compile(loss=contrastive_loss, optimizer=optimizer)\r\n",
        "print('Done')\r\n",
        "\r\n",
        "# load the trained weights from disk\r\n",
        "print(\"[INFO] Loading trained weights...\", end='')\r\n",
        "model.load_weights(MODEL_WEIGHTS_PATH)\r\n",
        "\r\n",
        "# or load existing trained model (.pb)\r\n",
        "# model = load_model('models/contrastive_siamese_model',  compile=False)\r\n",
        "print('Done')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[INFO] Compiling model...Done\n[INFO] Loading trained weights...Done\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643593261711
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility for Visualize Result"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(test_path):\r\n",
        "    # load templates\r\n",
        "    print(\"[INFO] Loading templates...\", end='')\r\n",
        "    dataset_name = os.path.basename(test_path)\r\n",
        "    template_path = f'templates/{dataset_name}'\r\n",
        "    templates = []\r\n",
        "    labels = []\r\n",
        "    templatePaths = list(list_images(template_path))\r\n",
        "\r\n",
        "    for path in templatePaths:\r\n",
        "        file = os.path.basename(path)\r\n",
        "        if file.startswith('template_'):\r\n",
        "            template_name = os.path.basename(path)\r\n",
        "            template = cv2.imread(path)\r\n",
        "            template = cv2.resize(template, (IMG_SHAPE[0], IMG_SHAPE[1]), interpolation = cv2.INTER_AREA)\r\n",
        "            template = img_to_array(template)\r\n",
        "            template = np.array(template, dtype='float')/255.0\r\n",
        "            template = np.expand_dims(template, axis=0)\r\n",
        "\r\n",
        "            # save normalized ID template and labels\r\n",
        "            templates.append((template, template_name))\r\n",
        "            labels.append(template_name.replace('template_','').split('.')[0])\r\n",
        "\r\n",
        "    print(f'Done ({len(templates)} loaded)')\r\n",
        "\r\n",
        "    # load query images\r\n",
        "    print(\"[INFO] Recognizing query images...\")\r\n",
        "\r\n",
        "    for path in os.listdir(test_path):\r\n",
        "        # ignore non-image files\r\n",
        "        if os.path.basename(path).split('.')[-1] in ['jpg','png','gif','bmp','tiff','webp']:\r\n",
        "            image = cv2.imread(os.path.join(test_path, path))\r\n",
        "            resize = cv2.resize(image, (IMG_SHAPE[0], IMG_SHAPE[1]), interpolation=cv2.INTER_AREA)\r\n",
        "            resize = img_to_array(resize)\r\n",
        "            resize = np.array(resize, dtype='float')/255.0\r\n",
        "            resize = np.expand_dims(resize, axis=0)\r\n",
        "\r\n",
        "            # perform One-Shot Learning on query images by feeding it through the trained SN\r\n",
        "            results = []\r\n",
        "\r\n",
        "            for idx, (template_object, label) in enumerate(zip(templates, labels)):\r\n",
        "                (template, template_name) = template_object\r\n",
        "                preds = model.predict([template, resize])\r\n",
        "                proba = preds[0][0]\r\n",
        "                \r\n",
        "                results.append((label, proba, template_name))\r\n",
        "\r\n",
        "            # sort difference score in asc order    \r\n",
        "            results.sort(key=lambda x: x[1], reverse=False)\r\n",
        "\r\n",
        "            # get best match result\r\n",
        "            best_match = results[0][0]\r\n",
        "            best_matched_template = results[0][2]\r\n",
        "            \r\n",
        "            # visualize result\r\n",
        "            tempalte_img = cv2.imread(os.path.join(template_path, best_matched_template))\r\n",
        "            images = [image, tempalte_img]\r\n",
        "            vu.show_images(images, ['Query', 'Template'], width=10, height=10)\r\n",
        "\r\n",
        "            print('Best Match:', best_match)\r\n",
        "            print('Candidates:', results, '\\n')\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify New Character Using Just One Example (i.e. Template)\r\n",
        "We will supply one example image to attempt classifying the unseen new characters\r\n",
        "\r\n",
        "![image-alt-text](icons/mario_icon.jpg)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test query image path\r\n",
        "test_path = 'test_images/mario'\r\n",
        "run_inference(test_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643601761831
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try on Megaman Series\r\n",
        "Recognizing main hero characters using one image\r\n",
        "\r\n",
        "![image-alt-text](icons/megaman_icon.jpg)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test query image path\r\n",
        "test_path = 'test_images/megaman'\r\n",
        "run_inference(test_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1643601640427
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}